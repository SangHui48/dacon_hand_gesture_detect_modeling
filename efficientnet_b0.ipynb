{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import remotezip as rz\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython import display\n",
    "from urllib import request\n",
    "# from tensorflow_docs.vis import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'FPS' : 30,\n",
    "    'IMG_SIZE': 128,\n",
    "    'EPOCHS': 10,\n",
    "    'LEARNING_RATE': 3e-4,\n",
    "    'BATCH_SIZE': 4,\n",
    "    'SEED': 41,\n",
    "    'FILES_PER_CLASS': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED']) # SEED 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>./train/TRAIN_000.mp4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>./train/TRAIN_001.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>./train/TRAIN_002.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>./train/TRAIN_003.mp4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>./train/TRAIN_004.mp4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                   path  label\n",
       "0  TRAIN_000  ./train/TRAIN_000.mp4      3\n",
       "1  TRAIN_001  ./train/TRAIN_001.mp4      0\n",
       "2  TRAIN_002  ./train/TRAIN_002.mp4      1\n",
       "3  TRAIN_003  ./train/TRAIN_003.mp4      4\n",
       "4  TRAIN_004  ./train/TRAIN_004.mp4      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['id'] == 'TRAIN_000']['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a78162fec4408e95088f559ba6da0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# modify data path for my directory case\n",
    "for i in tqdm(range(len(train))):\n",
    "    file_name = train.loc[i, 'path'].split('/')[-1]\n",
    "    train.loc[i, 'path'] = f'./data/train/{file_name}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>./data/train/TRAIN_000.mp4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>./data/train/TRAIN_001.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>./data/train/TRAIN_002.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>./data/train/TRAIN_003.mp4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>./data/train/TRAIN_004.mp4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                        path  label\n",
       "0  TRAIN_000  ./data/train/TRAIN_000.mp4      3\n",
       "1  TRAIN_001  ./data/train/TRAIN_001.mp4      0\n",
       "2  TRAIN_002  ./data/train/TRAIN_002.mp4      1\n",
       "3  TRAIN_003  ./data/train/TRAIN_003.mp4      4\n",
       "4  TRAIN_004  ./data/train/TRAIN_004.mp4      4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_per_class(df):\n",
    "    \"\"\" Retrieve the files that belong to each class.\n",
    "\n",
    "    Args:\n",
    "      files: List of files in the dataset.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary of class names (key) and files (values).\n",
    "    \"\"\"\n",
    "    files_for_class = collections.defaultdict(list)\n",
    "    for i in tqdm(range(len(df))):\n",
    "        label = df.loc[i, 'label']\n",
    "        files_for_class[label].append(df.loc[i, 'path'])\n",
    "    return files_for_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fb1afb2954424b99b1dbe8bd209a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files_for_class = get_file_per_class(train)\n",
    "classes = list(files_for_class.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 5\n",
      "Num videos for class[0]: 133\n"
     ]
    }
   ],
   "source": [
    "print('Num classes:', len(classes))\n",
    "print('Num videos for class[0]:', len(files_for_class[classes[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_subset_of_classes(files_for_class, classes, files_per_class):\n",
    "  \"\"\" Create a dictionary with the class name and a subset of the files in that class.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Dictionary of class names (key) and files (values).\n",
    "      classes: List of classes.\n",
    "      files_per_class: Number of files per class of interest.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary with class as key and list of specified number of video files in that class.\n",
    "  \"\"\"\n",
    "  files_subset = dict()\n",
    "\n",
    "  for class_name in classes:\n",
    "    class_files = files_for_class[class_name]\n",
    "    files_subset[class_name] = class_files[:files_per_class]\n",
    "\n",
    "  return files_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "files_subset = select_subset_of_classes(files_for_class, classes, CFG['FILES_PER_CLASS'])\n",
    "print(len(files_subset[classes[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_class_lists(files_for_class, count):\n",
    "  \"\"\" Returns the list of files belonging to a subset of data as well as the remainder of\n",
    "    files that need to be downloaded.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Files belonging to a particular class of data.\n",
    "      count: Number of files to download.\n",
    "\n",
    "    Returns:\n",
    "      Files belonging to the subset of data and dictionary of the remainder of files that need to be downloaded.\n",
    "  \"\"\"\n",
    "  split_files = []\n",
    "  remainder = {}\n",
    "  for cls in files_for_class:\n",
    "    split_files.extend(files_for_class[cls][:count])\n",
    "    remainder[cls] = files_for_class[cls][count:]\n",
    "  return split_files, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ufc_101_subset(zip_url, num_classes, splits, download_dir):\n",
    "  \"\"\" Download a subset of the UFC101 dataset and split them into various parts, such as\n",
    "    training, validation, and test.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL with a ZIP file with the data.\n",
    "      num_classes: Number of labels.\n",
    "      splits: Dictionary specifying the training, validation, test, etc. (key) division of data \n",
    "              (value is number of files per split).\n",
    "      download_dir: Directory to download data to.\n",
    "\n",
    "    Return:\n",
    "      Mapping of the directories containing the subsections of data.\n",
    "  \"\"\"\n",
    "  files = list_files_from_zip_url(zip_url)\n",
    "  for f in files:\n",
    "    path = os.path.normpath(f)\n",
    "    tokens = path.split(os.sep)\n",
    "    if len(tokens) <= 2:\n",
    "      files.remove(f) # Remove that item from the list if it does not have a filename\n",
    "\n",
    "  files_for_class = get_files_per_class(files)\n",
    "\n",
    "  classes = list(files_for_class.keys())[:num_classes]\n",
    "\n",
    "  for cls in classes:\n",
    "    random.shuffle(files_for_class[cls])\n",
    "\n",
    "  # Only use the number of classes you want in the dictionary\n",
    "  files_for_class = {x: files_for_class[x] for x in classes}\n",
    "\n",
    "  dirs = {}\n",
    "  for split_name, split_count in splits.items():\n",
    "    print(split_name, \":\")\n",
    "    split_dir = download_dir / split_name\n",
    "    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
    "    download_from_zip(zip_url, split_dir, split_files)\n",
    "    dirs[split_name] = split_dir\n",
    "\n",
    "  return dirs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 비디오 파일에서 프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_frames(frame, output_size):\n",
    "    \"\"\"\n",
    "    Pad and resize an image from a video.\n",
    "\n",
    "    Args:\n",
    "      frame: Image that needs to resized and padded. \n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      Formatted frame with padding of specified output size.\n",
    "    \"\"\"\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "    frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_from_video_file(video_path, n_frames, output_size = (128,128), frame_step = 30):\n",
    "  \"\"\"\n",
    "    Creates frames from each video file present for each category.\n",
    "\n",
    "    Args:\n",
    "      video_path: File path to the video.\n",
    "      n_frames: Number of frames to be created per video file.\n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
    "  \"\"\"\n",
    "  # Read each video frame by frame\n",
    "  result = []\n",
    "  src = cv2.VideoCapture(str(video_path))  \n",
    "\n",
    "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "  need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "  if need_length > video_length:\n",
    "    start = 0\n",
    "  else:\n",
    "    max_start = video_length - need_length\n",
    "    start = random.randint(0, max_start + 1)\n",
    "\n",
    "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "  ret, frame = src.read()\n",
    "  result.append(format_frames(frame, output_size))\n",
    "\n",
    "  for _ in range(n_frames - 1):\n",
    "    for _ in range(frame_step):\n",
    "      ret, frame = src.read()\n",
    "    if ret:\n",
    "      frame = format_frames(frame, output_size)\n",
    "      result.append(frame)\n",
    "    else:\n",
    "      result.append(np.zeros_like(result[0]))\n",
    "  src.release()\n",
    "  result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "  return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "075d2fee0e726cd55db21fee7f1e6111ee4ebdb9f86cd89da0b2348257ebd538"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
